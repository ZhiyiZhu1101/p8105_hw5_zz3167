---
title: "p8105_hw5_zz3167"
author: "Zhiyi Zhu"
date: "2023-11-08"
output: github_document
---

```{r setup, message = FALSE}
library(tidyverse)
library(broom)

knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = .6,
  out.width = "90%",
  message = FALSE, 
  warning = FALSE
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

```

## Problem 1

### Import data
```{r}
homicides_data = 
  read_csv("data/homicide-data.csv") |>
  janitor::clean_names()
```

### Describe the raw data 

* The data set contains `r nrow(homicides_data)` observations of `r ncol(homicides_data)` variables, which shows the details of homicides in 50 large U.S. cities.
* Each row represents a homicide record (identified by a `uid`), with information about the location of the killing (`city`, `state`, `lat` and `lon`), whether an arrest was made (`disposition`), and basic individual information about the victim (last and first name, race, age and sex).



```{r}
# create a city_state variable
homicides_data =
  homicides_data |>
  mutate(city_state = paste(city,',',state))

# summarize within cities to obtain the total number of homicides and the number of unsolved homicides 
homicides_number = 
  homicides_data |>
  group_by(city_state) |>
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest","Open/No arrest"))
    )

print(homicides_number)
```

### Estimate the proportion of homicides

```{r}
# estimate the proportion of homicides of Baltimore,MD
baltimore_df = 
  homicides_number |>
  filter(city_state == "Baltimore , MD")

baltimore_result  =
  prop.test(x = pull(baltimore_df, unsolved_homicides), 
            n = pull(baltimore_df, total_homicides),
            alternative = "two.sided",
            conf.level = 0.95, 
            correct = TRUE)|>
  broom::tidy()

baltimore_result

# save the output of prop.test as an R object
save(baltimore_result, file = "result/baltimore_result.RData")

# pull the estimated proportion and confidence intervals from the resulting tidy dataframe
baltimore_tidy = 
data.frame(
  city = 'Baltimore, MD',
  estimate = pull(baltimore_result, estimate),
  ci_lower = pull(baltimore_result, conf.low),
  ci_upper = pull(baltimore_result, conf.high)
) 

print(baltimore_tidy)
```

So, the estimated proportion is `r baltimore_tidy |> pull(estimate) |> round(3)`. The 95% confidence interval is `r paste('(', baltimore_tidy |> pull(ci_lower) |>round(3), ',', baltimore_tidy |> pull(ci_upper) |> round(3), ')')`

### Run prop.test for each of the cities

```{r}
unsolved_propotion = function(city_name) {
  city_number = 
    homicides_number |>
    filter(city_state == city_name)
  
  city_result = 
    prop.test(x = pull(city_number, unsolved_homicides), 
              n = pull(city_number, total_homicides)) |>
    broom::tidy() |>
    select(estimate, conf.low, conf.high)
  
  city_result
}

city_name = pull(homicides_number, city_state)

total_result = 
  data_frame(city_name) |>
  mutate(test_result = map(city_name, unsolved_propotion)) |>
  unnest(test_result)
  
total_result
```

### Create a plot that shows the estimates and CIs for each city

```{r}
total_result |>
  mutate(city_name = reorder(city_name, estimate)) |>
  ggplot(aes(x = estimate, y = city_name)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) +
  labs(x = "Estimate and 95% CI", 
       y = "City", 
       title = "Estimates and Confidence Intervals for Unsolved Homicides by City")
```

## Problem 2

Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time:

* Start with a dataframe containing all file names; the list.files function will help
* Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe
* Tidy the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary

```{r}
# File names
file_name = 
  list.files(path = "data/longitudinal/")

# Iterate over file names and read in data
longitudinal_df = 
  data_frame(file_name) |>
  mutate(
    file_path = str_c("data/longitudinal/", file_name),
    data = map(file_path, read_csv)) |>
  unnest(data) 

# Tidy the result
longitudinal_df = 
  longitudinal_df|>
  janitor::clean_names() |>
  separate(file_name, into = c("arm", "subject_id"), sep = "_") |>
  mutate(
    arm = case_match(
      arm, 
      "con" ~ "control", 
      "exp" ~ "experiment")) |>
  mutate(subject_id = str_replace(subject_id, ".csv", "")) |>
  pivot_longer(week_1:week_8, 
               names_to = "week",
               names_prefix = "week_",
               values_to = "observation") |>
  select(arm, subject_id, week, observation)

longitudinal_df
```

### Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups

```{r}
longitudinal_df |>
  ggplot(aes(x = week, y = observation, group = subject_id, color = subject_id)) +
  geom_point()+
  geom_line() +
  facet_grid(.~arm) +
  labs(x = "week",
       y = "observation",
       title = "Observation for Each Subject over Time")
```

* Comment: 
  * As can be seen from the plot, the experimental arm consistently shows a significantly higher value compared to the control arm .
  * Moreover, the observations for the control group fluctuates around a fixed value, whereas the observations for the experimental group generally shows a tendency to increase over time.

## Problem 3

First set the following design elements:
* Fix n=30
* Fix σ=5

Set μ=0. Generate 5000 datasets from the model: x∼Normal[μ,σ]

For each dataset, save μ^ and the p-value arising from a test of H:μ=0 using α=0.05.

### For mu = 0

```{r}
sim_test = function(mu){
  
  sim_data = rnorm(n = 30, mean = mu, sd = 5)
  
  sim_result = 
    t.test(sim_data) |>
    broom::tidy()|>
    select(estimate, p.value)
  
  return(sim_result)
}

mu_0_result = 
  expand_grid(
    mu = 0,
    iter = 1:5000
  ) |>
  mutate(result = map(mu, sim_test)) |>
  unnest(result)

mu_0_result
```

### For mu = 1,2,3,4,5,6 

Repeat the above for μ={1,2,3,4,5,6}, and complete the following:

* Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.
* Make a plot showing the average estimate of μ^ on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?

```{r}
total_sim_result = 
  expand.grid(mu = 1:6,iter = 1:5000) |>
  mutate(result = map(mu, sim_test)) |>
  unnest(result) |>
  bind_rows(mu_0_result)
```

### Make a plot showing the proportion of times the null was rejected

```{r}
total_sim_result |>
  group_by(mu) |>
  summarise(
    total = n(),
    reject_num = sum(p.value < 0.05)
  ) |>
  mutate(rejected_proportion = reject_num / total) |>
  ggplot(aes(x = mu, y = rejected_proportion)) +
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) + 
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(x = "True Mean", y = "Power", title = "Power of the test with Different True Means")
```

* Comment: 
  * Association between effect size and power: The plot illustrates that as the true mean increases, power also increases. In other words, the power rises with the effect size, ultimately approaching 1.

### Make a plot showing the average estimate of different true mean

```{r}
total_sim_result |>
  group_by(mu) |>
  summarise(mean_estimate = mean(estimate)) |>
  ggplot(aes(x = mu, y = mean_estimate)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  labs(x = "True mean",
       y = "Average of Estimated Mean",
       title = "Estimated Mean vs True Mean")
```

### Make a second plot the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis

```{r}
rejected_df = 
  total_sim_result |>
  filter(p.value < 0.05) |>
  group_by(mu) |>
  summarize(mean_estimate = mean(estimate))

total_df = 
  total_sim_result |>
  group_by(mu) |>
  summarize(mean_estimate = mean(estimate))

ggplot()+
  geom_point(data = total_df, aes(x = mu, y = mean_estimate, color = "All Estimate"))+
  geom_line(data = total_df, aes(x = mu, y = mean_estimate, color = "All Estimate"))+
  geom_point(data = rejected_df, aes(x = mu, y = mean_estimate, color = "Rejected Estimate")) +
  geom_line(data = rejected_df, aes(x = mu, y = mean_estimate, color = "Rejected Estimate"))+
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  scale_color_manual(values = c("Rejected Estimate" = "blue", "All Estimate" = "red")) +
  labs(x = "True mean",
       y = "Average of Estimated Mean",
       title = "All versus Rejected Estimates")
```

* Comment:
  * When the true mean is smaller than 4, the sample average estimate means for which the null is rejected are different from the true mean. This might because the effect size is small so the power is relatively low.
  * When the true mean is larger or equal to 4 , the sample average estimate means for which the null is rejected are similar to the true mean. This might because the power increases as the effect size increases.
